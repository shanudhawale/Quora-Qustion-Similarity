{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRP-fAQedMTd"
   },
   "source": [
    "<h2> 3.6 Featurizing text data with tfidf weighted word-vectors </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3IbomL8dMTi",
    "outputId": "3fa8eb7c-ddf2-4f98-edee-0c49db6502e8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# exctract word2vec vectors\n",
    "# https://github.com/explosion/spaCy/issues/1721\n",
    "# http://landinghub.visualstudio.com/visual-cpp-build-tools\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5XNgVyLdMT7"
   },
   "outputs": [],
   "source": [
    "# avoid decoding problems\n",
    "df = pd.read_csv(\"train.csv\")\n",
    " \n",
    "# encode questions to unicode\n",
    "# https://stackoverflow.com/a/6812069\n",
    "# ----------------- python 2 ---------------------\n",
    "# df['question1'] = df['question1'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# df['question2'] = df['question2'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# ----------------- python 3 ---------------------\n",
    "df['question1'] = df['question1'].apply(lambda x: str(x))\n",
    "df['question2'] = df['question2'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RU3HqJXwdMUj"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# merge texts\n",
    "questions = list(df['question1']) + list(df['question2'])\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=False, )\n",
    "tfidf.fit_transform(questions)\n",
    "\n",
    "# dict key:word and value:tf-idf score\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "2JKI2yT4dMUv"
   },
   "source": [
    "- After we find TF-IDF scores, we convert each question to a weighted average of word2vec vectors by these scores.\n",
    "- here we use a pre-trained GLOVE model which comes free with \"Spacy\".  https://spacy.io/usage/vectors-similarity\n",
    "- It is trained on Wikipedia and therefore, it is stronger in terms of word semantics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.0MB 123kB/s  eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: en-core-web-sm\n",
      "  Running setup.py bdist_wheel for en-core-web-sm ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/shanud6711/.cache/pip/wheels/6a/47/fb/6b5a0b8906d8e8779246c67d4658fd8a544d4a03a75520197a\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-2.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFS6m8z5dMUz",
    "outputId": "3c4fb6fd-7f86-4955-8b8f-762b5969ecce",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404290/404290 [1:00:15<00:00, 111.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# en_vectors_web_lg, which includes over 1 million unique vectors.\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "vecs1 = []\n",
    "\n",
    "for qu1 in tqdm(list(df['question1'])):\n",
    "    doc1 = nlp(qu1) \n",
    "    # 384 is the number of dimensions of vectors \n",
    "    mean_vec1 = np.zeros([len(doc1), 96])\n",
    "    for word1 in doc1:\n",
    "        # word2vec\n",
    "        vec1 = word1.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word1)]\n",
    "        except:\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec1 += vec1 * idf\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vecs1.append(mean_vec1)\n",
    "df['q1_feats_m'] = list(vecs1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62GEF-RbdMVB",
    "outputId": "60a4f5f8-5582-4886-befd-2ab6ed99c753"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404290/404290 [1:02:00<00:00, 108.67it/s]\n"
     ]
    }
   ],
   "source": [
    "vecs2 = []\n",
    "for qu2 in tqdm(list(df['question2'])):\n",
    "    doc2 = nlp(qu2) \n",
    "    mean_vec2 = np.zeros([len(doc1),96])\n",
    "    for word2 in doc2:\n",
    "        # word2vec\n",
    "        vec2 = word2.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word2)]\n",
    "        except:\n",
    "            #print word\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec2 += vec2 * idf\n",
    "    mean_vec2 = mean_vec2.mean(axis=0)\n",
    "    vecs2.append(mean_vec2)\n",
    "df['q2_feats_m'] = list(vecs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a38GBlGWdMVQ"
   },
   "outputs": [],
   "source": [
    "#prepro_features_train.csv (Simple Preprocessing Feartures)\n",
    "#nlp_features_train.csv (NLP Features)\n",
    "if os.path.isfile('nlp_features_train.csv'):\n",
    "    dfnlp = pd.read_csv(\"nlp_features_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download nlp_features_train.csv from drive or run previous notebook\")\n",
    "\n",
    "if os.path.isfile('df_fe_without_preprocessing_train.csv'):\n",
    "    dfppro = pd.read_csv(\"df_fe_without_preprocessing_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download df_fe_without_preprocessing_train.csv from drive or run previous notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apdRa1kndMVb"
   },
   "outputs": [],
   "source": [
    "df1 = dfnlp.drop(['qid1','qid2','question1','question2'],axis=1)\n",
    "df2 = dfppro.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df3 = df.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df3_q1 = pd.DataFrame(df3.q1_feats_m.values.tolist(), index= df3.index)\n",
    "df3_q2 = pd.DataFrame(df3.q2_feats_m.values.tolist(), index= df3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xzWAqGegdMVp",
    "outputId": "2f88eeda-244f-4bbb-a51c-a8680fe8fb92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>0.982759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>67</td>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "      <td>56</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  is_duplicate   cwc_min   cwc_max   csc_min   csc_max   ctc_min  \\\n",
       "0   0             0  0.999980  0.833319  0.999983  0.999983  0.916659   \n",
       "1   1             0  0.799984  0.399996  0.749981  0.599988  0.699993   \n",
       "2   2             0  0.399992  0.333328  0.399992  0.249997  0.399996   \n",
       "3   3             0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   4             0  0.399992  0.199998  0.999950  0.666644  0.571420   \n",
       "\n",
       "    ctc_max  last_word_eq  first_word_eq  abs_len_diff  mean_len  \\\n",
       "0  0.785709           0.0            1.0           2.0      13.0   \n",
       "1  0.466664           0.0            1.0           5.0      12.5   \n",
       "2  0.285712           0.0            1.0           4.0      12.0   \n",
       "3  0.000000           0.0            0.0           2.0      12.0   \n",
       "4  0.307690           0.0            1.0           6.0      10.0   \n",
       "\n",
       "   token_set_ratio  token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "0              100                93          93                 100   \n",
       "1               86                63          66                  75   \n",
       "2               66                66          54                  54   \n",
       "3               36                36          35                  40   \n",
       "4               67                47          46                  56   \n",
       "\n",
       "   longest_substr_ratio  \n",
       "0              0.982759  \n",
       "1              0.596154  \n",
       "2              0.166667  \n",
       "3              0.039216  \n",
       "4              0.175000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe of nlp features\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4DQnDtndMV4",
    "outputId": "2e288eed-e8fa-4ec3-a9b9-4e4daba52fc1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>word_Common</th>\n",
       "      <th>word_Total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>freq_q1+q2</th>\n",
       "      <th>freq_q1-q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  freq_qid1  freq_qid2  q1len  q2len  q1_n_words  q2_n_words  \\\n",
       "0   0          1          1     66     57          14          12   \n",
       "1   1          4          1     51     88           8          13   \n",
       "2   2          1          1     73     59          14          10   \n",
       "3   3          1          1     50     65          11           9   \n",
       "4   4          3          1     76     39          13           7   \n",
       "\n",
       "   word_Common  word_Total  word_share  freq_q1+q2  freq_q1-q2  \n",
       "0         10.0        23.0    0.434783           2           0  \n",
       "1          4.0        20.0    0.200000           5           3  \n",
       "2          4.0        24.0    0.166667           2           0  \n",
       "3          0.0        19.0    0.000000           2           0  \n",
       "4          2.0        20.0    0.100000           4           2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data before preprocessing \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1YIPtTwdMWC",
    "outputId": "510f4c73-0706-4633-d706-e0d348ebfa71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.179502</td>\n",
       "      <td>37.450734</td>\n",
       "      <td>-67.929891</td>\n",
       "      <td>32.224260</td>\n",
       "      <td>143.348841</td>\n",
       "      <td>135.374580</td>\n",
       "      <td>17.865204</td>\n",
       "      <td>54.562352</td>\n",
       "      <td>81.618952</td>\n",
       "      <td>232.909844</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.834681</td>\n",
       "      <td>-60.222836</td>\n",
       "      <td>-22.026407</td>\n",
       "      <td>103.336721</td>\n",
       "      <td>-68.477435</td>\n",
       "      <td>-54.976582</td>\n",
       "      <td>-67.802667</td>\n",
       "      <td>116.269998</td>\n",
       "      <td>60.515907</td>\n",
       "      <td>-12.245918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.236660</td>\n",
       "      <td>-80.371412</td>\n",
       "      <td>-45.785899</td>\n",
       "      <td>78.291651</td>\n",
       "      <td>183.568220</td>\n",
       "      <td>100.894079</td>\n",
       "      <td>74.344814</td>\n",
       "      <td>48.360800</td>\n",
       "      <td>127.297406</td>\n",
       "      <td>112.987303</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.130517</td>\n",
       "      <td>-98.080321</td>\n",
       "      <td>19.113786</td>\n",
       "      <td>-20.507512</td>\n",
       "      <td>-76.981003</td>\n",
       "      <td>82.665070</td>\n",
       "      <td>41.085575</td>\n",
       "      <td>129.377789</td>\n",
       "      <td>115.868471</td>\n",
       "      <td>4.383535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97.546825</td>\n",
       "      <td>22.972184</td>\n",
       "      <td>-39.558384</td>\n",
       "      <td>18.723420</td>\n",
       "      <td>56.928621</td>\n",
       "      <td>48.307634</td>\n",
       "      <td>8.719282</td>\n",
       "      <td>36.893752</td>\n",
       "      <td>106.899967</td>\n",
       "      <td>226.283079</td>\n",
       "      <td>...</td>\n",
       "      <td>-66.835018</td>\n",
       "      <td>87.592126</td>\n",
       "      <td>4.032439</td>\n",
       "      <td>56.851707</td>\n",
       "      <td>-43.625406</td>\n",
       "      <td>-57.580953</td>\n",
       "      <td>-50.425837</td>\n",
       "      <td>78.591990</td>\n",
       "      <td>105.714349</td>\n",
       "      <td>-33.304142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57.586979</td>\n",
       "      <td>-22.017081</td>\n",
       "      <td>-4.599306</td>\n",
       "      <td>-88.939274</td>\n",
       "      <td>-4.732172</td>\n",
       "      <td>-54.209051</td>\n",
       "      <td>74.614933</td>\n",
       "      <td>106.533731</td>\n",
       "      <td>15.520613</td>\n",
       "      <td>39.009704</td>\n",
       "      <td>...</td>\n",
       "      <td>28.362964</td>\n",
       "      <td>41.981225</td>\n",
       "      <td>-11.204994</td>\n",
       "      <td>16.833430</td>\n",
       "      <td>-36.372474</td>\n",
       "      <td>8.927553</td>\n",
       "      <td>-64.553190</td>\n",
       "      <td>95.054234</td>\n",
       "      <td>-34.157576</td>\n",
       "      <td>70.821923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.185766</td>\n",
       "      <td>-40.506968</td>\n",
       "      <td>-83.403915</td>\n",
       "      <td>-52.648649</td>\n",
       "      <td>79.074880</td>\n",
       "      <td>-19.038236</td>\n",
       "      <td>53.728726</td>\n",
       "      <td>97.648597</td>\n",
       "      <td>160.555808</td>\n",
       "      <td>290.541380</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.390929</td>\n",
       "      <td>109.604429</td>\n",
       "      <td>-91.160170</td>\n",
       "      <td>-25.739906</td>\n",
       "      <td>133.123054</td>\n",
       "      <td>-13.508796</td>\n",
       "      <td>-100.115195</td>\n",
       "      <td>208.424405</td>\n",
       "      <td>286.930891</td>\n",
       "      <td>68.027630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2          3           4           5   \\\n",
       "0  -6.179502  37.450734 -67.929891  32.224260  143.348841  135.374580   \n",
       "1   9.236660 -80.371412 -45.785899  78.291651  183.568220  100.894079   \n",
       "2  97.546825  22.972184 -39.558384  18.723420   56.928621   48.307634   \n",
       "3  57.586979 -22.017081  -4.599306 -88.939274   -4.732172  -54.209051   \n",
       "4  83.185766 -40.506968 -83.403915 -52.648649   79.074880  -19.038236   \n",
       "\n",
       "          6           7           8           9   ...         86          87  \\\n",
       "0  17.865204   54.562352   81.618952  232.909844  ... -71.834681  -60.222836   \n",
       "1  74.344814   48.360800  127.297406  112.987303  ... -32.130517  -98.080321   \n",
       "2   8.719282   36.893752  106.899967  226.283079  ... -66.835018   87.592126   \n",
       "3  74.614933  106.533731   15.520613   39.009704  ...  28.362964   41.981225   \n",
       "4  53.728726   97.648597  160.555808  290.541380  ...  -4.390929  109.604429   \n",
       "\n",
       "          88          89          90         91          92          93  \\\n",
       "0 -22.026407  103.336721  -68.477435 -54.976582  -67.802667  116.269998   \n",
       "1  19.113786  -20.507512  -76.981003  82.665070   41.085575  129.377789   \n",
       "2   4.032439   56.851707  -43.625406 -57.580953  -50.425837   78.591990   \n",
       "3 -11.204994   16.833430  -36.372474   8.927553  -64.553190   95.054234   \n",
       "4 -91.160170  -25.739906  133.123054 -13.508796 -100.115195  208.424405   \n",
       "\n",
       "           94         95  \n",
       "0   60.515907 -12.245918  \n",
       "1  115.868471   4.383535  \n",
       "2  105.714349 -33.304142  \n",
       "3  -34.157576  70.821923  \n",
       "4  286.930891  68.027630  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questions 1 tfidf weighted word2vec\n",
    "df3_q1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wUMdkJTNdMWL",
    "outputId": "69e3e256-cbb8-4fe2-aaf2-9088c3868b29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-14.616961</td>\n",
       "      <td>59.755496</td>\n",
       "      <td>-53.263741</td>\n",
       "      <td>19.514483</td>\n",
       "      <td>113.916494</td>\n",
       "      <td>101.657068</td>\n",
       "      <td>8.561492</td>\n",
       "      <td>66.232771</td>\n",
       "      <td>32.888134</td>\n",
       "      <td>210.812740</td>\n",
       "      <td>...</td>\n",
       "      <td>-72.266623</td>\n",
       "      <td>-37.072061</td>\n",
       "      <td>-31.142731</td>\n",
       "      <td>94.064858</td>\n",
       "      <td>-45.053226</td>\n",
       "      <td>-34.155226</td>\n",
       "      <td>-76.548091</td>\n",
       "      <td>99.282783</td>\n",
       "      <td>50.791735</td>\n",
       "      <td>-17.566246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.565752</td>\n",
       "      <td>-16.844562</td>\n",
       "      <td>-130.911787</td>\n",
       "      <td>0.320241</td>\n",
       "      <td>79.350263</td>\n",
       "      <td>23.562032</td>\n",
       "      <td>79.124558</td>\n",
       "      <td>84.119844</td>\n",
       "      <td>128.684146</td>\n",
       "      <td>279.539867</td>\n",
       "      <td>...</td>\n",
       "      <td>6.193168</td>\n",
       "      <td>-65.084206</td>\n",
       "      <td>-15.654533</td>\n",
       "      <td>-3.475830</td>\n",
       "      <td>26.999822</td>\n",
       "      <td>170.172597</td>\n",
       "      <td>-57.038937</td>\n",
       "      <td>194.269548</td>\n",
       "      <td>128.207809</td>\n",
       "      <td>55.490069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156.833635</td>\n",
       "      <td>59.991907</td>\n",
       "      <td>-8.414309</td>\n",
       "      <td>29.251429</td>\n",
       "      <td>133.680214</td>\n",
       "      <td>112.457563</td>\n",
       "      <td>89.849790</td>\n",
       "      <td>21.613006</td>\n",
       "      <td>24.331765</td>\n",
       "      <td>171.114489</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.185222</td>\n",
       "      <td>-19.283222</td>\n",
       "      <td>75.602445</td>\n",
       "      <td>24.144021</td>\n",
       "      <td>-91.874393</td>\n",
       "      <td>-178.454113</td>\n",
       "      <td>-91.471484</td>\n",
       "      <td>19.922710</td>\n",
       "      <td>21.266688</td>\n",
       "      <td>49.574857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.472446</td>\n",
       "      <td>56.717314</td>\n",
       "      <td>31.530609</td>\n",
       "      <td>-5.520159</td>\n",
       "      <td>33.454808</td>\n",
       "      <td>79.596186</td>\n",
       "      <td>15.509003</td>\n",
       "      <td>40.042088</td>\n",
       "      <td>21.094026</td>\n",
       "      <td>101.998123</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.779016</td>\n",
       "      <td>30.152287</td>\n",
       "      <td>49.300139</td>\n",
       "      <td>27.783794</td>\n",
       "      <td>25.937190</td>\n",
       "      <td>-32.107066</td>\n",
       "      <td>-3.817625</td>\n",
       "      <td>-14.231002</td>\n",
       "      <td>4.772116</td>\n",
       "      <td>7.711626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.446979</td>\n",
       "      <td>-4.338253</td>\n",
       "      <td>-70.196203</td>\n",
       "      <td>-48.636356</td>\n",
       "      <td>18.356850</td>\n",
       "      <td>-50.807065</td>\n",
       "      <td>24.311191</td>\n",
       "      <td>60.043682</td>\n",
       "      <td>32.421990</td>\n",
       "      <td>57.148700</td>\n",
       "      <td>...</td>\n",
       "      <td>36.089470</td>\n",
       "      <td>47.193193</td>\n",
       "      <td>-49.969586</td>\n",
       "      <td>44.796025</td>\n",
       "      <td>39.740805</td>\n",
       "      <td>-33.763316</td>\n",
       "      <td>-98.282342</td>\n",
       "      <td>22.118792</td>\n",
       "      <td>68.802085</td>\n",
       "      <td>21.025380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1           2          3           4           5   \\\n",
       "0  -14.616961  59.755496  -53.263741  19.514483  113.916494  101.657068   \n",
       "1   -3.565752 -16.844562 -130.911787   0.320241   79.350263   23.562032   \n",
       "2  156.833635  59.991907   -8.414309  29.251429  133.680214  112.457563   \n",
       "3   41.472446  56.717314   31.530609  -5.520159   33.454808   79.596186   \n",
       "4  -14.446979  -4.338253  -70.196203 -48.636356   18.356850  -50.807065   \n",
       "\n",
       "          6          7           8           9   ...         86         87  \\\n",
       "0   8.561492  66.232771   32.888134  210.812740  ... -72.266623 -37.072061   \n",
       "1  79.124558  84.119844  128.684146  279.539867  ...   6.193168 -65.084206   \n",
       "2  89.849790  21.613006   24.331765  171.114489  ... -26.185222 -19.283222   \n",
       "3  15.509003  40.042088   21.094026  101.998123  ... -17.779016  30.152287   \n",
       "4  24.311191  60.043682   32.421990   57.148700  ...  36.089470  47.193193   \n",
       "\n",
       "          88         89         90          91         92          93  \\\n",
       "0 -31.142731  94.064858 -45.053226  -34.155226 -76.548091   99.282783   \n",
       "1 -15.654533  -3.475830  26.999822  170.172597 -57.038937  194.269548   \n",
       "2  75.602445  24.144021 -91.874393 -178.454113 -91.471484   19.922710   \n",
       "3  49.300139  27.783794  25.937190  -32.107066  -3.817625  -14.231002   \n",
       "4 -49.969586  44.796025  39.740805  -33.763316 -98.282342   22.118792   \n",
       "\n",
       "           94         95  \n",
       "0   50.791735 -17.566246  \n",
       "1  128.207809  55.490069  \n",
       "2   21.266688  49.574857  \n",
       "3    4.772116   7.711626  \n",
       "4   68.802085  21.025380  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questions 2 tfidf weighted word2vec\n",
    "df3_q2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ozz83vh4dMWU",
    "outputId": "e5b30f77-2849-4b08-9949-0912ec0db418"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in nlp dataframe : 17\n",
      "Number of features in preprocessed dataframe : 12\n",
      "Number of features in question1 w2v  dataframe : 96\n",
      "Number of features in question2 w2v  dataframe : 96\n",
      "Number of features in final dataframe  : 221\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features in nlp dataframe :\", df1.shape[1])\n",
    "print(\"Number of features in preprocessed dataframe :\", df2.shape[1])\n",
    "print(\"Number of features in question1 w2v  dataframe :\", df3_q1.shape[1])\n",
    "print(\"Number of features in question2 w2v  dataframe :\", df3_q2.shape[1])\n",
    "print(\"Number of features in final dataframe  :\", df1.shape[1]+df2.shape[1]+df3_q1.shape[1]+df3_q2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HmfZ5Q1zdMWl"
   },
   "outputs": [],
   "source": [
    "# storing the final features to csv file\n",
    "if not os.path.isfile('final_features.csv'):\n",
    "    df3_q1['id']=df1['id']\n",
    "    df3_q2['id']=df1['id']\n",
    "    df1  = df1.merge(df2, on='id',how='left')\n",
    "    df2  = df3_q1.merge(df3_q2, on='id',how='left')\n",
    "    result  = df1.merge(df2, on='id',how='left')\n",
    "    result.to_csv('final_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3.Q_Mean_W2V.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
